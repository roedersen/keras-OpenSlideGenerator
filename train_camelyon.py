'''Train a simple deep CNN on the polygonal annotated slides using OpenSlideGenerator.
'''

from __future__ import print_function
from matplotlib import cm
from matplotlib import pyplot as plt
import tensorflow as tf
import tensorflow.keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.optimizers import RMSprop
import os
import math

import openslide_generator

print("Definition generator")
# create generator instance
gen_train = openslide_generator.OpenSlideGenerator('C:/Users/arno/Documents/fourthbrain/capstone/data/labels/labels_train.txt', \
        'C:/Users/arno/Documents/fourthbrain/capstone/data/training/', 128, 64, fetch_mode='label', label_to_use=1) #512, 256)

print("gen_train defined")

gen_val = openslide_generator.OpenSlideGenerator('C:/Users/arno/Documents/fourthbrain/capstone/data/labels/labels_val.txt', \
                'C:/Users/arno/Documents/fourthbrain/capstone/data/training/', 512, 256)

print("gen_val defined")

#gen_train.fetch_mode = 'area' #'label-slide'
print(f'fetch_mode: {gen_train.fetch_mode}')

#batch = next(gen_train.flow(batch_size=32))

#example = gen_train.get_example(1)
#print(example[0].shape)
#print(example[1])
#print(example[2])
#positions = dict()
#gen_train.reset_fetch_count()
#for i in range(2000):
#    if i % 500 == 0:
#        print(i)
#    _, label, (slide_id, region_id, posx, posy) = gen_train.get_example(i)
#    if not slide_id in positions:
#        positions[slide_id] = []
#    positions[slide_id].append((posx, posy, label))


batch_size = 32 #50
num_classes = len(gen_train.labels[gen_train.label_to_use])
epochs = 1
data_augmentation = False
num_predictions = 20
save_dir = os.path.join(os.getcwd(), 'saved_models')
model_name = 'keras_openslide_trained_model.h5'
t_steps = math.ceil(gen_train.patch_per_epoch/batch_size)
v_steps = math.ceil(gen_val.patch_per_epoch/batch_size)

print(f't_steps: {t_steps}')
print(f'v_steps: {v_steps}')

# model construction
model = Sequential()
model.add(Conv2D(32, (3, 3), padding='same',
                 input_shape=gen_train.shape()))
model.add(Activation('relu'))
model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), padding='same'))
model.add(Activation('relu'))
model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes))
model.add(Activation('softmax'))

# initiate RMSprop optimizer
opt = RMSprop(learning_rate=0.0001, decay=1e-6)

# Let's train the model using RMSprop
model.compile(loss='categorical_crossentropy',
              optimizer=opt,
              metrics=['accuracy'])

print("model compile successful")
# Fit the model on the batches generated by datagen.flow().
model.fit(gen_train.flow(batch_size=batch_size),
                    steps_per_epoch=t_steps,
                    epochs=epochs,
                    validation_data=gen_val.flow(batch_size=batch_size),
                    validation_steps=v_steps,
                    workers=1,
                    verbose=1)

#model.fit(gen_train.flow(batch_size=batch_size),
#                    steps_per_epoch=t_steps,
#                    epochs=epochs,
#                    workers=1,
#                    verbose=1)

print("model trained")
# Save model and weights
if not os.path.isdir(save_dir):
    os.makedirs(save_dir)
model_path = os.path.join(save_dir, model_name)
model.save(model_path)
print('Saved trained model at %s ' % model_path)
